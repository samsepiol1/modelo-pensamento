# Avaliação de Modelos

O que é um bom modelo? O indicador de avaliação mais importante é a capacidade de generalização do modelo, também conhecida como a precisão da previsão do modelo que lida com dados comerciais reais. Há também alguns indicadores de engenharia que podem ser usados para avaliar o modelo: interpretabilidade, que descreve o grau de previsibilidade direta dos resultados de previsão do modelo; taxa de previsão, que se refere ao tempo médio que o modelo leva para prever cada amostra; plasticidade, que se refere à aceitabilidade da taxa de previsão do modelo no processo real de negócios à medida que o volume de negócios se expande.

&#x20;O objetivo da aprendizagem da máquina é tornar o modelo aprendido aplicável a novas amostras, não apenas em amostras de treinamento. A capacidade do modelo aprendido de se aplicar a novas amostras é a chamada capacidade de generalização, também abordada como robustez. A diferença entre o resultado previsto do modelo aprendido na amostra e o resultado verdadeiro da amostra é chamada de erro. O erro de treinamento refere-se ao erro do modelo no conjunto de treinamento, e o erro de generalização refere-se ao erro do modelo na nova amostra (conjunto de teste). Obviamente, queremos ter um modelo com erro de generalização menor. Uma vez formado o modelo, todas as funções possíveis construirão um espaço, que é chamado de espaço de hipóteses. O algoritmo de aprendizado da máquina pode ser visto como um algoritmo que busca uma função adequada no espaço de hipóteses. Um modelo matemático que é muito simples, ou o tempo de treinamento é muito curto, causará um erro crescente de treinamento para o modelo. Este fenômeno é chamado underfitting. Para o primeiro, ele deve usar um modelo mais complexo para o treinamento; para o segundo, ele só precisa estender o tempo para eliminar efetivamente o underfitting. Entretanto, para determinar com precisão a causa do underfitting, muitas vezes é necessária certa experiência e métodos. Pelo contrário, se o modelo for muito complexo, pode levar a um pequeno erro de treinamento, mas a uma capacidade de generalização mais fraca, o que significa um erro de generalização maior conhecido como overfitting.&#x20;

Há muitos métodos para reduzir a superfitting. Os comuns incluem a simplificação adequada do modelo, o término do treinamento antes que o overfitting ocorra, e o uso de dropout e decadência de peso.  A capacidade de um modelo refere-se a sua capacidade de se adequar a uma variedade de funções,também conhecida como a complexidade de um modelo. Quando a capacidade é compatível com a complexidade da tarefa e a quantidade de dados de treinamento fornecidos, o algoritmo geralmente terá o melhor desempenho. Um modelo com capacidade insuficiente não pode lidar com
